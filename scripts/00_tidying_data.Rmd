---
title: "Tidying data"
author: "Rich Cottrell"
date: "15/02/2022"
output: html_document
editor_options: 
  markdown: 
    wrap: 72
---

######### DO NOT RUN UNLESS YOU HAVE ACCESS TO UTAS SUSTAINABLE AQUAFEEDS PROJECT RDSI DRIVE #########

This script takes the raw_data from databases and publications (much of
which is stored in the rdsi storage at UTAS) and tidies it to be useable
for this project. Spatial products are stored here("data/spatial"), some
raw_data products which are not modified or summarised but format has
been adjusted e.g. wide to long format are here("data/raw_data") and new
(non-spatial) data products from this analysis are stored
here("data/tidy_data"). There are exceptions, some data products such as
the embodied forage fish demand per cell file are not pushed to Github
because of their size (see .gitignore) but can be provided on request.

```{r}
library(tidyverse)
library(parallel)
library(janitor)
library(here)
library(countrycode)
library(terra)
library(data.table)
library(dtplyr)
library(future)
library(furrr)
library(readxl)
#install.packages("/Users/rsc2/Downloads/ncdf4_1.21.tgz", repos = NULL)

source(here("src/directories.R"))

select <- dplyr::select

#uncomment depending if using one drive
#rdsi_dir <- rdsi_backup_dir

```

Create a base raster to be used throughout the project. Gall Peters
projection is used for equal area analysis without the issues of
'falling off the edge that mollweide has'. Can be reporjected for
aesthetics at a later point.

```{r}

base_raster <- rast()
values(base_raster) <- 1:ncell(base_raster)
base_raster_ea <- project(base_raster, equal_area_gp_proj)
res(base_raster_ea) <- 10000
values(base_raster_ea) <- 1:ncell(base_raster_ea) 

writeRaster(x = base_raster_ea, file = here("data/spatial/base_raster_gall_peters.tif"), overwrite=TRUE)




```

#AQUACULTURE DATA

Tidy global aquaculture production data

```{r}

(aqua_prod_raw <- 
   read_csv(file.path(fishstat_dir, "aqua-prod-raw.csv")) %>% 
  clean_names() %>% 
  rename(country= country_name,
         species = asfis_species_name,
         area = fao_major_fishing_area_name,
         environment = environment_name) %>% 
   dplyr::select(-unit_name) %>% 
   filter(!country %in% c("Totals - Tonnes - live weight", "FAO. 2021. Fishery and Aquaculture Statistics. Global aquaculture production 1950-2019 (FishstatJ). In: FAO Fisheries Division [online]. Rome. Updated 2021. www.fao.org/fishery/statistics/software/fishstatj/en"))
)


flags <- aqua_prod_raw %>% 
  dplyr::select(-starts_with("x")) %>% 
  pivot_longer(names_to = "flag", values_to = "symbol", -c(country, species, area, environment, unit)) %>% 
  mutate(flag = case_when(symbol == "..." ~ "No data",
                           symbol == " " ~ "Data not separately available",
                           symbol == "-" ~ "Nil or zero",
                           symbol == "0 0" ~ "0<x<0.5",
                           symbol == "E" ~ "estimate",
                           is.na(symbol) ~ "Reported")) %>% 
  dplyr::select(-symbol)


#sorts country coding to deal with non-UTF characters that country code depends on
Encoding(aqua_prod_raw$country) <- "latin1" #deals with the non-UTF
aqua_prod_raw$country <- iconv(aqua_prod_raw$country, "latin1", "UTF-8",sub='')



aquaculture_prod <- 
  
  bind_cols(
    aqua_prod_raw %>%
      dplyr::select(-c(starts_with("s_"), s)) %>% 
      pivot_longer(names_to = "year", values_to = "value", cols = -c(country, species, area, environment, unit)) %>% 
      mutate(iso_3c = countrycode(country, origin = "country.name", destination = "iso3c", warn = TRUE)) %>%
      mutate(iso_3c = case_when(country == "Zanzibar" ~ "TZA",
                                TRUE ~ iso_3c)) %>%
      mutate(year = gsub("x", "", year) %>% 
               as.numeric),
    
    flags %>% dplyr::select(flag)
  ) %>% 
  drop_na(iso_3c)



saveRDS(object = aquaculture_prod, file = here("data", "tidy_data", "aquaculture_production_tidy.rds"))



```

Bring feed composition data into project

```{r}

feed_composition <- read_csv(file.path(rdsi_raw_data_dir, "/feed/feed_composition_pressures.csv"))

write_csv(x = feed_composition, file = here("data/raw_data/feed_composition_pressures.csv"))



```

# AGRICULTURE DATA

This is the code to unzip and adjust the extents of the mapspam rasters
(-180, 180, -90, 90) - DO NOT RUN IN PROJECT - here as a backup to
scripts in the raw data files

```{r}
mapspam_zip_files <- list.files(path = mapspam_dir, pattern = "\\.zip$")


lapply(X=mapspam_zip_files, FUN = unzip)


#Adjust the extent of rasters to full lon lat coveragge

#test
banana <- raster(file.path(mapspam_dir, "spam2010V2r0_global_H_BANA_H.tif"))
banana

#this should be the new extent for all
new_extent <- c(-180, 180, -90, 90)

extent(banana) <- new_extent

#apply new extents to all files

tifs <- list.files(mapspam_dir, pattern = "\\.tif", full.names = TRUE)

adjust_extent <- \(this_filename){
  
  this_file <- basename(this_filename)
  message(paste("processing", which(tifs==this_file), "of", length(tifs)))
  this_raster <- rast(this_filename)
  ext(this_raster) <- new_extent
  writeRaster(x=this_raster, filename = file.path("/mnt/rdsi/raw_data/MAPSPAM/new-extents", this_file), overwrite = TRUE)
}

#run over mutliple cores to speed things up - pointer error but all files ran.
parallel::mclapply(X = tifs, FUN = adjust_extent, mc.cores = detectCores()-2)
```

This chunk of code brings in the crop production and yield rasters (only
the production layers for all types) and reprojects to equal area
projections for each crop)

```{r}

crop_demand <- readRDS(here("data/tidy_data/demand/total_crop_demand.rds"))

crop_list <- unique(crop_demand$map_spam_code)

crop_production_files <- list.files(file.path(mapspam_dir, "new-extents"), full.names = TRUE)[grep(pattern = "_P_", list.files(file.path(mapspam_dir, "new-extents"), full.names = TRUE))] 

these_crop_production_files <- crop_production_files[grepl("MAIZ_A|OPUL_A|WHEA_A|RAPE_A|OOIL_A|SOYB_A|SUNF_A", crop_production_files)]


#for testing the below function
this_code <- crop_list[[1]]
this_filepath <- these_crop_production_files[[5]]


#NOTE::: the function below runs fine (i.e. raster files are reprojected and produced) but introducing terra spat rasters instead of raster::rasters created an error "Error in x@ptr$nrow() : external pointer is not valid" when printing the raster. Still searching for solutions. It is to do with parallelisng SpatRaster see - https://github.com/rspatial/terra/issues/166 . So have switched to lapply to make sure code runs.

lapply(X = these_crop_production_files, FUN = \(this_filepath){
  
  this_file <- basename(this_filepath)
      
    #import the raster
    imported_file <- rast(this_filepath)
    
    #aggregate the file
    aggregated_file <-  terra::aggregate(imported_file, fact = 6)
    
    #write the original and the  to this project
    writeRaster(imported_file, filename = paste0(here("data/spatial/crop-layers-raw/"), this_file), overwrite = TRUE)
    writeRaster(aggregated_file, filename = paste0(here("data/spatial/crop-layers-reprojected/"), this_file), overwrite=TRUE)
  
  
})
  

#this code is need for the physical area layers stuff in the biodiversity paper so leaving in for now. 
    #imported_file <- imported_file*0.01 #converts the imported raster to km2 from ha 
    


#Pull in the MAPSPAM Yield Data from RDSI 
these_crop_yield_files <- list.files(file.path(mapspam_dir, "new-extents"), pattern = "_Y_", full.names = TRUE)
these_crop_yield_files <- these_crop_yield_files[grepl("MAIZ_A|OPUL_A|WHEA_A|RAPE_A|OOIL_A|SOYB_A|SUNF_A", these_crop_yield_files)]

this_file <- these_crop_yield_files[[1]]


map(.x = these_crop_yield_files, .f = \(this_file){
  
  this_rast <- rast(this_file)
  
  this_agg_rast <- terra::aggregate(this_rast, fact=6, fun=sum)
  
  raw_saveName <- sprintf(here("data/spatial/crop-layers-raw/%s"), basename(this_file))
  saveName <-  sprintf(here("data/spatial/crop-layers-reprojected/%s"), basename(this_file))
  
  if(!file.exists(saveName)){
    
    writeRaster(x = this_rast, filename = raw_saveName, overwrite = TRUE)
    writeRaster(x = this_agg_rast, filename = saveName, overwrite = TRUE)
    
  }
})

#Pull in the MAPSPAM Area Data from RDSI 

these_crop_area_files <- list.files(file.path(mapspam_dir, "new-extents"), pattern = "_A_", full.names = TRUE)
these_crop_area_files <- these_crop_area_files[grepl("MAIZ_A|OPUL_A|WHEA_A|RAPE_A|OOIL_A|SOYB_A|SUNF_A", these_crop_area_files)]

this_file <- these_crop_area_files[[1]]

map(.x = these_crop_area_files, .f = \(this_file){
  
  this_rast <- rast(this_file)
  
  this_agg_rast <- terra::aggregate(this_rast, fact=6, fun=sum)*0.01 #aggregate to half degree and convert to km2
  
  raw_saveName <- sprintf(here("data/spatial/crop-layers-raw/%s"), basename(this_file))
  saveName <-  sprintf(here("data/spatial/crop-layers-reprojected/%s"), basename(this_file))
  
  if(file.exists(saveName)){
    
    writeRaster(x = this_rast, filename = raw_saveName, overwrite = TRUE)
    writeRaster(x = this_agg_rast, filename = saveName, overwrite = TRUE)
    
  }
}) 

```


Tidy FAOSTAT Production data

```{r}

production_raw <- read_csv(file.path(rdsi_dir, "raw_data/fao/FAOSTAT_2022/Production_Crops_Livestock_E_All_Data_(Normalized).csv"))

production_flags <- read_csv(file.path(rdsi_dir, "raw_data/fao/FAOSTAT_2022/Production_Crops_Livestock_E_Flags.csv"))

production_raw <- production_raw |> 
  left_join(production_flags) |> 
  mutate(Description = if_else(is.na(Description), true = "Official data", false = Description)) |> 
  mutate(Sector = case_when(grepl("Milk|milk|Meat|meat|Fat|fat|Chicken|Buffaloes|Cattle|cattle|Camel|ffal|Pigs|abbit|worm|odent|urkey|oghurt|Wool|Sheep|Goat|Egg|egg|Asses|Beeh|Bees|Ducks|Cream|Geese|Horses|Honey|Lard|Mules|Birds|Skins|Butter|Cheese|Snail", Item) ~ "Livestock",
                            TRUE ~ "Crops"))

Encoding(production_raw$Area) <- "latin1" #deals with the non-UTF
production_raw$Area <- iconv(production_raw$Area, "latin1", "UTF-8",sub='')


#separate by sector
production_sector_list <- 
  production_raw  |> 
  clean_names()  |>  
  mutate(iso3c = countrycode(area, origin = "country.name", destination = "iso3c", warn = TRUE)) |> 
  group_split(sector)

#save
map(.x = production_sector_list, .f = function(this_element){
  saveRDS(object = this_element, file = sprintf(here("data/tidy_data/production-data/%s_production_tidy.rds"), tolower(unique(this_element$sector))))
})
  



```

 Tidying crop LCA files to include as a single file

```{r}

#bring in all LCA files from RDSI (prepped in Teams) and save in this project



list.files(file.path(rdsi_raw_data_dir, "LCA/Crops - ReCiPe 2016 Midpoint"), pattern = ".csv", full.names =TRUE) |> 
  map(\(each_file){
    
    saveName <- basename(each_file)
    
    this_file <- read_csv(each_file)
    
    write_csv(this_file, file = sprintf(here("data/raw_data/LCA/%s"), saveName))
  })

each_file <- list.files(here("data/raw_data/LCA"), pattern = "allocation", full.names = TRUE)[[2]]

lca_all_crops <- 
  list.files(here("data/raw_data/LCA"), pattern = "allocation", full.names = TRUE) |> 
  map_df(\(each_file){
    
    message("Processing", each_file)
    
    
    this_file <- read_csv(each_file) #|> rename_at(vars(1:3), make_clean_names)
    
    this_files_allocation <- str_extract(each_file, pattern = "ge_allocation|mass_allocation|econ_allocation")
    
    this_long_file <- this_file |> 
      pivot_longer(names_to = "iso2c", values_to = "value" , cols = -c(raw_material, impact, unit)) |> 
      mutate(iso3c = countrycode(sourcevar = iso2c, origin = "iso2c", destination = "iso3c", warn = TRUE)) |> 
      mutate(allocation = this_files_allocation)
      # mutate(iso3c = case_when(iso2c == "UK" ~ "GBR",
      #                          grepl("US-", iso2c) ~ "USA",
      #                          TRUE ~ iso3c))
    }) %>% 
  mutate(FAOSTAT_name = case_when(raw_material == "Broad bean" ~ "Broad beans, horse beans, dry",
                                  raw_material == "Guar bean" ~ "Pulses nes",
                                  raw_material == "Lupins" ~ "Pulses nes - Lupins",
                                  raw_material == "Peas" ~ "Peas, dry",
                                  raw_material == "Wheat grain" ~ "Wheat",
                                  TRUE ~ raw_material)) |> 
  mutate(value_tonne = value*1000)
  

saveRDS(object = lca_all_crops, file = here("data/tidy_data/LCA/crop_lca.rds"))


unique(lca_all_crops$FAOSTAT_name)


#Tidying the processing LCA files

#test the function below
#this_ingredient_excel <- list.files(file.path(rdsi_raw_data_dir, "LCA/Processing_MidPoint/"), full.names = TRUE)[[1]]

processing_pressures <- 
  list.files(file.path(rdsi_raw_data_dir, "LCA/Processing_MidPoint"), full.names = TRUE) |> 
  map_df(.f = \(this_ingredient_excel){
    
    this_ingredient <- tools::file_path_sans_ext(basename(this_ingredient_excel))
    
    this_excel <- read_excel(this_ingredient_excel) 
    
    this_economic_excel <- this_excel |> 
      select(1,2, contains("Economic")) |> 
      rename_at(vars(-c(1,2)), ~str_extract(.x,"(?<=\\{).+?(?=\\})")) |> 
      mutate(ingredient = this_ingredient,
             allocation = "econ_allocation") |> 
      rename(impact = 1,
             unit =2) |> 
      pivot_longer(names_to = "iso2c", values_to = "value", cols =  -c(ingredient, allocation, impact, unit))
    
    this_energy_excel <- this_excel |> 
      select(1,2, contains("Energy")) |> 
       rename_at(vars(-c(1,2)), ~str_extract(.x,"(?<=\\{).+?(?=\\})")) |> 
      mutate(ingredient = this_ingredient,
             allocation = "ge_allocation") |>
      rename(impact = 1,
             unit =2)|> 
      pivot_longer(names_to = "iso2c", values_to = "value", cols =  -c(ingredient, allocation, impact, unit))
    
    this_mass_excel <- this_excel |> 
      select(1,2, contains("Mass")) |> 
       rename_at(vars(-c(1,2)), ~str_extract(.x,"(?<=\\{).+?(?=\\})")) |> 
      mutate(ingredient = this_ingredient,
             allocation = "mass_allocation") |> 
      rename(impact = 1,
             unit =2)|> 
      pivot_longer(names_to = "iso2c", values_to = "value", cols =  -c(ingredient, allocation, impact, unit))
    
    
  bind_rows(this_economic_excel, this_energy_excel, this_mass_excel) |> 
    mutate(iso3c = countrycode(sourcevar = iso2c, origin = "iso2c", destination = "iso3c", warn=TRUE)) |> 
    relocate(ingredient, .before = impact) |> 
    mutate(value_tonne = value*1000)
    
    
  })

saveRDS(object = processing_pressures, file = here("data/tidy_data/LCA/processing_LCA.rds"))


```

# FISHERIES DATA


Pulling together the spatial industrial fisheries data and save to rdsi
storage.

```{r}

#THE v5 DATA

catch <- fread(file.path(watson_dir, "v5.0/Catch2015_2019.csv")) |> lazy_dt(immutable = FALSE) |> filter(IYear == 2017) |> as.data.table()

codes_cell <- fread(file.path(watson_dir, "v5.0/Codes_cells.csv")) |> lazy_dt(immutable = FALSE)

codes_country <- fread(file.path(watson_dir, "v5.0/Codes_country.csv"))|> lazy_dt(immutable = FALSE)

codes_gear <- fread(file.path(watson_dir, "v5.0/Codes_gear.csv")) |> lazy_dt(immutable = FALSE) |> select(Gear, FleetGearName, VBDesc) |> distinct() 

codes_taxa <- fread(file.path(watson_dir, "v5.0/Codes_taxa.csv")) |> lazy_dt(immutable = FALSE)


catch_joined<- catch |> 
  lazy_dt(immutable = FALSE) |> 
  left_join(codes_cell, by = "Cell") |>
  left_join(codes_country, by = c("CNumber" = "Cnumber")) |>
  left_join(codes_gear, by = c("Gear")) |>
  left_join(codes_taxa, by = "Taxonkey") |>
  rename(CountryName = `FAO name`) |> as.data.table()

fwrite(catch_joined, file.path(watson_dir, "v5.0/watson_2017_fisheries_catch.csv"))


# THE V4 DATA

# catch <- fread(file.path(watson_dir, "v4/Catch2015_2019.csv")) |> lazy_dt() |> filter(IYear == 2017)
# 
# codes_cell <- fread(file.path(watson_dir, "v4/codes_cells.csv")) |> lazy_dt()
# 
# codes_country <- fread(file.path(watson_dir, "v4/codes_country.csv"))|> lazy_dt()
# 
# codes_gear <- fread(file.path(watson_dir, "v4/codes_gear.csv")) |> select(Gear, FleetGearName) |> distinct() |> lazy_dt()
# 
# codes_taxa <- fread(file.path(watson_dir, "v4/codes_taxa.csv")) |> lazy_dt()
# 
# IndexInd <- fread(file.path(watson_dir, "v4/IndexInd.csv")) |> lazy_dt()
# 

# index_2015 <- 
#   IndexInd |> 
#   filter(IYear == 2015) |> 
#   left_join(codes_taxa, by = c("Taxonkey" = "TaxonKey")) |> 
#   left_join(codes_gear |> select(-c(VBCode, FAOGearName, FAOGearCode)) |> distinct(), by = c("Gear", "FGearCode")) |> 
#   left_join(codes_country, by = c("CNumber" = "Country")) |> 
#   select(-c(NumCells, Reported, IUUTotal, Discards))
#   
#  
# catch_index_join <- catch_coords_2015 |> 
#   left_join(index_2015) |> 
#   mutate(total_catch = Reported + IUU) |> 
#   as.data.table() 


#fwrite(catch_index_join, file.path(watson_dir, "watson_2015_fisheries_catch.csv"))


```

Filter FAO Species lists for forage fish spp

```{r}
fao_list <- read_csv(file.path(fao_dir, "species_lists/CL_FI_SPECIES_GROUPS.csv"))

unique(fao_list$ISSCAAP_Group)

forage_list <- fao_list |> filter(ISSCAAP_Group == "Herrings, sardines, anchovies" )

write_csv(forage_list, here("data/raw_data/fisheries/fao_forage_fish_spp_list.csv"))
```

Pull in allocation data from Kok et al (economic allocation on forage fish) and synthesised data from Teams for gross energy and mass calculation.

Interesting paper by Ayer, Tyedmers et al on the benefits of gross
energy allocation
<https://link.springer.com/content/pdf/10.1065/lca2006.11.284.pdf>

```{r}
# Pull in all allocation factor data

crop_allocation_factors <- 
  read_csv(file.path(rdsi_dir, "raw_data/allocation/crop_ingredient_allocation_factors.csv")) |> 
  select(ingredient, item, gaez_code, mass_allocation_factor, ge_allocation_factor, econ_allocation_factor) |> 
  distinct() |> 
  mutate(item = case_when(item == "Soya beans" ~ "Soybeans",
                          item == "Maize (corn)" ~ "Maize", 
                          item == "Other pulses n.e.c." ~ "Pulses nes",
                          item == "Broad beans and horse beans, dry" ~ "Broad beans, horse beans, dry",
                          item == "Rape or colza seed" ~ "Rapeseed",
                          TRUE ~ item)) |> 
  write_csv(file = here("data/tidy_data/allocation/crop_ingredient_allocation_factors.csv"))


forage_allocation_factors <- 
  read_csv(file.path(rdsi_dir, "raw_data/allocation/forage_fish_allocation_factors.csv")) |> 
  select(CommonName, sci_name, ingredient, mass_value, ge_value, econ_value) |> 
  rename(common_name = CommonName,
         mass_allocation_factor = mass_value,
         ge_allocation_factor = ge_value,
         econ_allocation_factor = econ_value) |> 
  distinct() |> 
  write_csv(file = here("data/tidy_data/allocation/forage_fish_allocation_factors.csv"))
  
  
trimmings_allocations_factors <- 
  read_csv(file.path(rdsi_dir, "raw_data/allocation/trimmings_allocation_factors.csv")) |> 
  rename(mass_allocation_factor = mass_byproduct_cf,
         ge_allocation_factor = ge_byproduct_cf,
         econ_allocation_factor = econ_byproduct_cf) |> 
  select(common_name, sci_name, ingredient, mass_allocation_factor, ge_allocation_factor, econ_allocation_factor) |> 
  distinct() |> 
  drop_na() |> 
  write_csv(file = here("data/tidy_data/allocation/trimmings_allocation_factors.csv"))



# ingredient_cf_data <- read_csv("/mnt/rdsi/raw_data/allocation/top_crop_producers_conversions.csv")
# write_csv(ingredient_cf_data, here("data/tidy_data/production-data/top_crop_producers_conversions.csv"))  
# 
# cf_coproduct_data <- read_csv("/mnt/rdsi/raw_data/allocation/coproduct_conversions.csv") |> select(ingredient, coproduct,country, coproduct_cf)
# write_csv(x = cf_coproduct_data, file = here("data/raw_data/allocation/coproduct_conversions.csv"))
# 
# ge_values <- read_csv("/mnt/rdsi/raw_data/allocation/feed_coproduct_ge_allocation.csv") |> 
#   mutate(coproduct = if_else(ingredient == "guar meal", true = "guar gum", false = coproduct)) 
# write_csv(ge_values, file = here("data/raw_data/allocation/feed_coproduct_ge_allocation.csv"))
# 


```

Tidy embodied fish data from FMFO for different forage fish species
from Kok et al 'Fish as feed: Using economic allocation to quantify the
Fish In : Fish Out ratio of major fed aquaculture species' in
Aquaculture.

Data source:
<https://www.sciencedirect.com/science/article/pii/S0044848620309741>
Appendix A Supplementary Data

```{r}
kok_etal_data <- read_csv(here("data/raw_data/fisheries/embodied_fish_kok_et_al.csv")) |> 
  mutate(Species = substring(Species, 1, nchar(Species)-1)) |> 
  mutate(common_name = case_when(grepl("Sandeels|Capelin|Boarfish", Species) ~ word(Species, start = 1, end = 1),
                                 grepl("South American pilchard", Species) ~ word(Species, start = 1, end = 3),
                                 TRUE ~ word(Species, start = 1, end = 2))) |> 
  mutate(common_name = case_when(grepl("bnchovy", common_name)~ "Peruvian anchovy",
                                TRUE ~ common_name)) |> 
  mutate(sci_name = c(unlist(str_extract_all(Species,  "(?<=\\().+?(?=\\))")), rep(NA, times = 2))) |> 
  mutate(sci_name = case_when(sci_name == "C. harengus" ~ "Clupea harengus",
                              sci_name == "M. villosus" ~ "Mallotus villosus",
                              TRUE~sci_name)) |> 
  select(-Species) |> 
  relocate(c(common_name, sci_name), .before = `Ecosystem d`)

write_csv(kok_etal_data, file = here("data/raw_data/fisheries/embodied_fish_ratio_tidy.csv"))

# now tidy gross energy and mass allocation data synthesised for this project.
allocation_raw <- 
  #rdsi
  #read_csv("/mnt/rdsi/raw_data/allocation/embodied_fish_allocation.csv") |> 
  #onedrive
  read_csv("/Users/rsc2/OneDrive - University of Tasmania/ARC Linkage - Optimising aquafeeds/rdsi/raw_data/allocation/embodied_fish_allocation.csv") |> 
  select(CommonName, sci_name, fishmeal_yield, fish_oil_yield, ingredient, ge_fmfo, ge_part, ge_value, mass_part, mass_value) 


write_csv(allocation_raw, file = here("data/raw_data/allocation/embodied_fish_allocation_tidy.csv"))


```

Filter Watson spatialised catch data for forage fish species so it can
be stored in the project.

Data source: Watson v5.0 provided by request. v4.0 is publicly available
through IMAS Research Data Portal
<https://metadata.imas.utas.edu.au/geonetwork/srv/eng/catalog.search#/metadata/5c4590d3-a45a-4d37-bf8b-ecd145cb356d>

```{r}

#THE V5 DATA

catch <- 
 # fread(file.path(watson_dir, "v5.0/watson_2017_fisheries_catch.csv")) # 
  fread("/Users/rsc2/OneDrive - University of Tasmania/ARC Linkage - Optimising aquafeeds/rdsi/raw_data/watson_2015/v5.0/watson_2017_fisheries_catch.csv")


# 
#  #145 unique species and species groups in the FAO data
# forage_spp_fao <- read_csv(here("data/raw_data/fisheries/fao_forage_fish_spp_list.csv")) |> select(Name_en, Scientific_Name) |> distinct() |> rename(common_name = Name_en, sci_name = Scientific_Name) 
# 
# #bring in species highlighted in the SI of Froehlich et al 2018 Avoiding the ecological limits of forage fish. Nature Sustainability.
froehlich_spp <-
  #RDSI
 # read_csv("/mnt/rdsi/raw_data/froehlich/forage_fish_spp.csv")
# One Drive
  read_csv("/Users/rsc2/OneDrive - University of Tasmania/ARC Linkage - Optimising aquafeeds/rdsi/raw_data/froehlich/forage_fish_spp.csv")

froehlich_binomials <- froehlich_spp |> filter(resolution == "binomial") |> mutate(common_name = NA) |> select(common_name, sci_name)
# 
# 
# #13 species in Kok et al - some not in the FAO data
 forage_spp_koketal <- read_csv(here("data/raw_data/fisheries/embodied_fish_ratio_tidy.csv")) |> drop_na() |>  select(common_name, sci_name) |> distinct()
forage_spp_koketal_common <- read_csv(here("data/raw_data/fisheries/embodied_fish_ratio_tidy.csv")) |> drop_na() |>  pull(common_name) |> unique()

#bind the two sources and save - 155 species considered in total
forage_spp_list <- bind_rows(froehlich_binomials ,forage_spp_koketal) |>  distinct()
write_csv(forage_spp_list, here("data/raw_data/fisheries/forage_fish_list_final.csv"))

forage_catch <- catch |>
  filter(foragefish == 1 | TaxonName %in% forage_spp_list$sci_name  | CommonName %in% forage_spp_list$common_name) |> 
  as_tibble() |> 
  filter(ReportedIND >0) |> 
  #assume that gears targeting small or medium pelagic or benthopelagic species and krill are targeted e.g Halpern, Parker et al.
  filter(Descript %in% c("pelagic 30 - 90 cm" ,  "pelagic <30 cm", "benthopelagic 30 - 90 cm", "krill")) |> 
  #following Cashion et al https://onlinelibrary.wiley.com/doi/full/10.1111/faf.12222?saml_referrer, restrict gears to purse seine, seine nets, boat seines, bottom trawls, mid-water trawks
  filter(VBDesc %in% c("purse seines",  "seine nets", "boat seines", "bottom trawls",  "mid-water trawls"))

#27 million tonnes, represented by 79 species across industrial and non industrial sources
sum(forage_catch$ReportedIND) #26.5 millions tonnes from industrial
sum(forage_catch$ReportedNIND) #428154 is from industrial
unique(forage_catch$TaxonName) # 79 species

tibble(Common_name = unique(forage_catch$CommonName), Species_binomial = unique(forage_catch$TaxonName))

saveRDS(forage_catch, file = here("data/large_data/spatial_forage_catch_2017.rds"))

```

## Fisheries data for trimmings

```{r}

fisheries_catch <- readRDS("data/input/watson_w_codes.rds") |> as_tibble()

trimmings_spp <- read_csv("/mnt/rdsi/raw_data/biomar/trimmings_spp_list.csv") |> filter(common_name != "Antarctic krill")

trimmings_spp_catch <- 
  fisheries_catch |> 
  filter(CommonName %in% trimmings_spp$common_name | TaxonName %in% trimmings_spp$scientific_name | grepl("Sardinella", CommonName) | grepl("Sardinella", TaxonName)| grepl("Engraulis", TaxonName)|  grepl("nchovy", CommonName) | CommonName %in% c( "Anchoveta", "Anchovies") | CommonName == "Alaska pollack" | CommonName == "Blue whiting" | grepl("Sprat|sprat", CommonName))

trimmings_spp_catch |> pull(CommonName) |> unique()

saveRDS(trimmings_spp_catch, file = "data/input/trimmings_spp_catch.rds")



trimmings_contributions <- read_csv(file.path(rdsi_dir, "raw_data/biomar/trimmings_share_by_spp.csv")) |> 
  rename(CommonName = spp) |> 
  mutate(CommonName = gsub("\\s*\\([^\\)]+\\)", "", CommonName)) |> 
  mutate(group = case_when(grepl("sprat|Sprat", CommonName) ~ "Sprats",
                           grepl("anchovy|anchoita|Anchovies|anchoveta|Anchovy", CommonName) ~ "Anchovies",
                           grepl("Tuna|tuna|Albacore", CommonName) ~ "Tunas",
                           grepl("cod|pollack|Pollock", CommonName) ~ "Cods",
                            grepl("sardinella|Sardinella|sardine", CommonName) ~ "Sardines",
                           grepl("mackerel", CommonName) ~ "Mackerels",
                           grepl("herring|Herring", CommonName) ~ "Herrings",
                           grepl("menhaden|Mehaden", CommonName) ~ "Menhaden",
                           grepl("Capelin", CommonName) ~ "Capelin",
                           grepl("Blue whiting|Blue Whiting", CommonName) ~ "Blue whiting",
                           grepl("Sandeel", CommonName) ~ "Sandeel")) |> 
  drop_na(group) |> 
  write_csv(here("data/tidy_data/demand/trimmings_weightings.csv"))



```



## Fishing effort

Tidy Global fishing watch data.

Data source:
<https://globalfishingwatch.org/data-download/datasets/public-fishing-effort>
Files: fleet-daily-csvs-100-v2-2017.zip, fish-vessels-v2.csv,
README-fleet-v2.txt

First we can summarise the efort hours per day and bind it together.

```{r}

daily_effort_files <- list.files(file.path(gfw_dir, "fleet-daily-csvs-100-v2-2017"), pattern = ".csv", full.names = TRUE)

#summarise effort by day

effort_by_daygearcell <- 
  map_df(.x = daily_effort_files, .f = \(this_effort_filepath){
    
    
  saveName <-  paste0("summarised_", basename(this_effort_filepath))  
  
  this_counter <- which(daily_effort_files == this_effort_filepath)

  this_days_data <- fread(this_effort_filepath) 
  
  #this_days_data <- read_csv(this_effort_filepath, col_types = "Dddccddn")
  
  this_days_summarised_data <- 
    this_days_data |> 
    lazy_dt(immutable = FALSE) |> 
    group_by(cell_ll_lat, cell_ll_lon, geartype) |> 
    summarise(total_fishing_hrs = sum(fishing_hours, na.rm = TRUE)) |> 
    ungroup() |> 
    mutate(day = this_counter) |> 
    as.data.table()
  
  return(this_days_summarised_data)
  
}) 

#summarised annually - seems to be the same number of rows - could be the number of 0s
effort_by_gearcell2017 <- 
  effort_by_daygearcell |> 
  lazy_dt(immutable = FALSE) |> 
  group_by(cell_ll_lat, cell_ll_lon, geartype) |> 
  summarise(total_fishing_hrs = sum(total_fishing_hrs)) |> 
  as.data.table()


fwrite(x = effort_by_gearcell2017, file = here("data/tidy_data/pressures/fishing-effort/annual_effort_2017.csv"))

```

Explore the GFW data for gear types partitioning across gears and output
effort rasters for destructive methods for the benthos.

From Mel's script in the OHI_Science/food_systems folder the following
gear types are used:

Geartypes: - fishing: a combination of vessels of unknown fishing gear -
drifting_longlines: drifting longlines - seiners: vessels using seine
nets, including potential purse seine vessels targeting tuna and other
species, as well as danish and other seines - purse_seines: purse
seines, both pelagic and demersal - tuna_purse_seines: large purse
seines primarily fishing for tuna. - other_purse_seines: purse seiners
fishing for mackerel, anchovies, etc, often smaller and operating nearer
the coast than tuna purse seines. - other_seines: danish seines and
other seiners not using purse seines. - trawlers: trawlers, all types -
pole_and_line: vessel from which people fish with pole and line. -
trollers: vessel that tows multiple fishing lines. - fixed_gear: a
category that includes potential set longlines, set gillnets, and pots
and traps - pots_and_traps: vessel that deploys pots (small, portable
traps) or traps to catch fish - set_longlines: vessel that fishes by
setting longlines anchored to the seafloor. These lines have shorter
hooked, typically baited, lines hanging from them - set_gillnets: vessel
that fishes by setting gillnets anchored to the seafloor. -
dredge_fishing: vessel that tows a dredge the scrapes up edible bottom
dwellers such as scallops or oysters. - squid_jigger: squid jiggers,
mostly large industrial pelagic operating vessels

The influence of unknown fishing gears ('fishing' above) was addressed
in Halpern et al as a small source of uncertainty. See issue here
<https://github.com/OHI-Science/global_food_issues/issues/303>

```{r}

effort_summary <- fread(here("data/tidy_data/pressures/fishing-effort/annual_effort_2017.csv"))

#nearly 50% of all fishing effort is trawling (yikes), another 20% is drifting longlines
effort_summary |> 
  lazy_dt(immutable = TRUE) |> 
  group_by(geartype) |> 
  summarize(total_fishing_hrs = sum(total_fishing_hrs, na.rm=TRUE)) |> 
  arrange(-total_fishing_hrs) |> 
  mutate(prop_hrs = total_fishing_hrs/sum(total_fishing_hrs)) |> 
  as.data.table() 


#create raster of all fishing effort
total_map <- 
  effort_summary |> 
  lazy_dt(immutable = FALSE) |> 
  group_by(cell_ll_lon, cell_ll_lat) |> 
  summarize(total_fishing_hrs = sum(total_fishing_hrs, na.rm = TRUE)) |> 
  rename(lat = cell_ll_lat,
         lon = cell_ll_lon) |> 
  select(lon, lat, total_fishing_hrs) |> data.frame()
  
total_effort_r <- rast(total_map, type = "xyz", crs = crs(rast()))
plot(log10(total_effort_r+1))


#we are only interested in destructive gears for the benthic elemnt of disturbance so isolate maps for trawling and dredging

#trawling

trawl_map <- 
  effort_summary |> 
  lazy_dt(immutable = FALSE) |> 
  filter(geartype %in% c("trawlers")) |> 
  group_by(cell_ll_lon, cell_ll_lat) |> 
  summarize(total_fishing_hrs = sum(total_fishing_hrs, na.rm = TRUE)) |> 
  rename(lat = cell_ll_lat,
         lon = cell_ll_lon) |> 
  select(lon, lat, total_fishing_hrs) |> data.frame()
  
trawl_effort_r <- rast(trawl_map, type = "xyz", crs = crs(rast()))

trawl_effort_r <- extend(trawl_effort_r, ext(rast(res=0.01)), filename = here("data/spatial/03-fisheries-effort/gfw_annual_effort_2017_trawlers.tif"), overwrite=TRUE)
plot(log10(trawl_effort_r+1))



#dredging (much less prevalent)

dredge_map <- 
  effort_summary |> 
  lazy_dt(immutable = FALSE) |> 
  filter(geartype %in% c("dredge_fishing")) |> 
  group_by(cell_ll_lon, cell_ll_lat) |> 
  summarize(total_fishing_hrs = sum(total_fishing_hrs, na.rm = TRUE)) |> 
  rename(lat = cell_ll_lat,
         lon = cell_ll_lon) |> 
  select(lon, lat, total_fishing_hrs) |> data.frame()
  
dredge_effort_r <- rast(dredge_map, type = "xyz", crs = crs(rast()))
dredge_effort_r <- extend(dredge_effort_r, ext(rast(res=0.01)), filename = here("data/spatial/03-fisheries-effort/gfw_annual_effort_2017_dredge.tif"), overwrite=TRUE)
plot(log10(dredge_effort_r+1))




```

# Bring in rob parker data from rdsi storage in raw_data

```{r}
#importing the join data from downloaded data in RDSI storage
parker_gear_join <- read_csv(file.path(food_systems_data_dir, "parker_gear_join.csv"))

#alternatively it can be dowloaded from here when the food systems project is published
#parker_gear_join <- read_csv("https://raw.githubusercontent.com/OHI-Science/food_systems/master/fisheries/marine/ghg/int/gear_index_parker.csv?token=GHSAT0AAAAAABWBCADKLIWM2Y6WTU7X6FXAYWFFRVQ")


write_csv(parker_gear_join, file = here("data/raw_data/fisheries/parker_gear_join.csv"))



#Bring emissions intensity data from Parker et al 2018 stored in RDSI and save to project
ei_data <- 
  fread(file.path(food_systems_data_dir, "`all_catch_emissions_2017.csv`")) |> 
  lazy_dt(immutable = FALSE) |> 
  select(Taxonkey, Descript, species_class_int, species_class_fin, ParkerGearName = gear_type, ei_kgco2_kgcatch) |> 
  distinct() |> 
  arrange(ParkerGearName)|> 
  as_tibble()
  
write_csv(x= ei_data, file = here("data/large_data/all_catch_emissions_2017.csv"))




```

#NPP

Import the global net primary productivity data from NPP synthesis repo. Taken from the VGPM model using MODIS found here http://orca.science.oregonstate.edu/2160.by.4320.monthly.xyz.vgpm.m.chl.m.sst.php 



```{r}
# install.packages("BiocManager")
# BiocManager::install("rhdf5")

npp_2013_2022 <- rast(file.path(rdsi_dir, ("github/npp_synthesis/data/npp_2013_2022_mean.tif"))) |> 
  writeRaster(filename = here("data/spatial/00-net-primary-productivity/npp_2013_2022_mean.tif"), overwrite=TRUE)

npp_2013_2022_max <- rast(file.path(rdsi_dir, ("github/npp_synthesis/data/npp_2013_2022_max.tif"))) |> writeRaster(filename = here("data/spatial/00-net-primary-productivity/npp_2013_2022_max.tif"), overwrite=TRUE)



```

Bring in species for sourcing FMFO trimmings

```{r}

fisheries_catch <- readRDS(here("data/large_data/watson_w_codes.rds")) |> as_tibble()
#RDSI version
#trimmings_spp <- read_csv("/mnt/rdsi/raw_data/biomar/trimmings_spp_list.csv") |> filter(common_name != "Antarctic krill")
#OneDrive version
trimmings_spp <- read_csv("/Users/rsc2/OneDrive - University of Tasmania/ARC Linkage - Optimising aquafeeds/rdsi/raw_data/biomar/trimmings_spp_list.csv") |> filter(common_name != "Antarctic krill")


trimmings_spp_catch <- 
  fisheries_catch |> 
  filter(CommonName %in% trimmings_spp$common_name | TaxonName %in% trimmings_spp$scientific_name | grepl("Sardinella", CommonName) | grepl("Sardinella", TaxonName)| grepl("Engraulis", TaxonName)|  grepl("nchovy", CommonName) | CommonName %in% c( "Anchoveta", "Anchovies") | CommonName == "Alaska pollack" | CommonName == "Blue whiting" | grepl("Sprat|sprat", CommonName) |grepl("enhaden", CommonName))

trimmings_spp_catch |> pull(CommonName) |> unique()

saveRDS(trimmings_spp_catch, file = here("data/large_data/trimmings_spp_catch.rds"))

```


Import the raw trimmings conversion file and tidy, separating CommonName and scientific name

```{r}

trimmings_conversions <- 
   read_csv("/Users/rsc2/OneDrive - University of Tasmania/ARC Linkage - Optimising aquafeeds/rdsi/raw_data/allocation/trimmings_allocation.csv") |> 
  #read_csv("/mnt/rdsi/raw_data/allocation/trimmings_allocation.csv") |> 
  rename(CommonName = species) |> 
  mutate(TaxonName = gsub(".*(?:\\((.*)\\)).*|.*", "\\1",  str_extract(CommonName, "\\(([^()]*)\\)"))) |> 
  relocate(TaxonName, .before = fishmeal_yield) |> 
  mutate(CommonName = gsub("\\s*\\([^\\)]+\\)", "", CommonName)) |> 
  mutate(group = case_when(grepl("sprat", CommonName) ~ "Sprats",
                           grepl("anchovy|anchoita|Anchovies|anchoveta", CommonName) ~ "Anchovies",
                           grepl("Tuna|tuna|Albacore", CommonName) ~ "Tunas",
                           grepl("cod|pollack", CommonName) ~ "Cods",
                            grepl("sardinella|Sardinella|sardine", CommonName) ~ "Sardines",
                           grepl("mackerel", CommonName) ~ "Mackerels",
                           grepl("herring", CommonName) ~ "Herrings",
                           grepl("menhaden", CommonName) ~ "Menhaden",
                           grepl("Capelin", CommonName) ~ "Capelin",
                           grepl("Blue whiting", CommonName) ~ "Blue whiting"))

saveRDS(trimmings_conversions, here("data/tidy_data/allocation/trimmings_conversion_factors.csv"))

```


Trimmings sensitivity import into project

```{r}

trimmings_sensitivity <- 
  read_csv(file.path(rdsi_dir, "raw_data/allocation/trimmings_cf_sensitivity.csv")) |> 
  pivot_longer(values_to = "cf", names_to = "species", cols = -c(`trim price`)) |> 
  mutate(species_name = case_when(grepl("AP", species) ~ "Alaska pollock",
                                  grepl("BW", species) ~ "Blue whiting",
                                  grepl("AC", species) ~ "Atlantic cod",
                                  grepl("CA", species) ~ "Capelin"),
         ingredient = case_when(grepl("(fm)", species) ~ "Fishmeal",
                                TRUE ~ "Fish oil")) |> 
  select(-species)


saveRDS(object = trimmings_sensitivity, file = here("data/tidy_data/allocation/trimmings_conversion_sensitvity.rds"))
```


Bring in ecosystem transfer efficiency data into project
```{r}

 read_csv(file.path(rdsi_dir, "raw_data/cashion/ecosystem_te.csv")) |> 
  write_csv(here("data/tidy_data/ecosystem-te/ecosystem_te.csv"))
  

```


