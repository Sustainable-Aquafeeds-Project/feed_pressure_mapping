---
title: "Tidying data"
author: "Rich Cottrell"
date: "15/02/2022"
output: html_document
---

This script takes the raw_data from databases and publications (much of which is stored in the rdsi storage at UTAS) and tidies it to be useable for this project. Spatial products are stored here("data/spatial"), some raw_data products which are not modified or summarised but format has been adjusted e.g. wide to long format are here("data/raw_data") and new (non-spatial) data products from this analysis are stored here("data/tidy_data"). There are exceptions, some data products such as the embodied forage fish demand per cell file are not pushed to Github because of their size (see .gitignore) but can be provided on request.


```{r}
library(tidyverse)
library(parallel)
library(janitor)
library(here)
library(countrycode)
library(rredlist)
library(terra)
library(data.table)
library(dtplyr)
library(future)
library(furrr)

source(here("src/directories.R"))
source(here("src/spatial.R"))

```


Create a base raster to be used throughout the project. Gall Peters projection is used for equal area analysis without the issues of 'falling off the edge that mollweide has'. Can be reporjected for aesthetics at a later point.
```{r}

base_raster <- rast()
values(base_raster) <- 1:ncell(base_raster)
base_raster_ea <- project(base_raster, equal_area_gp_proj)
res(base_raster_ea) <- 10000
values(base_raster_ea) <- 1:ncell(base_raster_ea) 

writeRaster(x = base_raster_ea, file = here("data/spatial/base_raster_gall_peters.tif"), overwrite=TRUE)




```


#AQUACULTURE DATA

Tidy global aquaculture production data

```{r}

(aqua_prod_raw <- 
   read_csv(file.path(fishstat_dir, "aqua-prod-raw.csv")) %>% 
  clean_names() %>% 
  rename(country= country_name,
         species = asfis_species_name,
         area = fao_major_fishing_area_name,
         environment = environment_name) %>% 
   dplyr::select(-unit_name) %>% 
   filter(!country %in% c("Totals - Tonnes - live weight", "FAO. 2021. Fishery and Aquaculture Statistics. Global aquaculture production 1950-2019 (FishstatJ). In: FAO Fisheries Division [online]. Rome. Updated 2021. www.fao.org/fishery/statistics/software/fishstatj/en"))
)


flags <- aqua_prod_raw %>% 
  dplyr::select(-starts_with("x")) %>% 
  pivot_longer(names_to = "flag", values_to = "symbol", -c(country, species, area, environment, unit)) %>% 
  mutate(flag = case_when(symbol == "..." ~ "No data",
                           symbol == " " ~ "Data not separately available",
                           symbol == "-" ~ "Nil or zero",
                           symbol == "0 0" ~ "0<x<0.5",
                           symbol == "E" ~ "estimate",
                           is.na(symbol) ~ "Reported")) %>% 
  dplyr::select(-symbol)


#sorts country coding to deal with non-UTF characters that country code depends on
Encoding(aqua_prod_raw$country) <- "latin1" #deals with the non-UTF
aqua_prod_raw$country <- iconv(aqua_prod_raw$country, "latin1", "UTF-8",sub='')



aquaculture_prod <- 
  
  bind_cols(
    aqua_prod_raw %>%
      dplyr::select(-c(starts_with("s_"), s)) %>% 
      pivot_longer(names_to = "year", values_to = "value", cols = -c(country, species, area, environment, unit)) %>% 
      mutate(iso_3c = countrycode(country, origin = "country.name", destination = "iso3c", warn = TRUE)) %>%
      mutate(iso_3c = case_when(country == "Zanzibar" ~ "TZA",
                                TRUE ~ iso_3c)) %>%
      mutate(year = gsub("x", "", year) %>% 
               as.numeric),
    
    flags %>% dplyr::select(flag)
  ) %>% 
  drop_na(iso_3c)



saveRDS(object = aquaculture_prod, file = here("data", "tidy_data", "aquaculture_production_tidy.rds"))



```

#AGRICULTURE DATA


This is the code to unzip and adjust the extents of the mapspam rasters (-180, 180, -90, 90) - DO NOT RUN IN PROJECT - here as a backup to scripts in the raw data files

```{r}
mapspam_zip_files <- list.files(path = mapspam_dir, pattern = "\\.zip$")


lapply(X=mapspam_zip_files, FUN = unzip)


#Adjust the extent of rasters to full lon lat coveragge

#test
banana <- raster(file.path(mapspam_dir, "spam2010V2r0_global_H_BANA_H.tif"))
banana

#this should be the new extent for all
new_extent <- c(-180, 180, -90, 90)

extent(banana) <- new_extent

#apply new extents to all files

tifs <- list.files(mapspam_dir, pattern = "\\.tif", full.names = TRUE)

adjust_extent <- \(this_filename){
  
  this_file <- basename(this_filename)
  message(paste("processing", which(tifs==this_file), "of", length(tifs)))
  this_raster <- rast(this_filename)
  ext(this_raster) <- new_extent
  writeRaster(x=this_raster, filename = file.path("/mnt/rdsi/raw_data/MAPSPAM/new-extents", this_file), overwrite = TRUE)
}

#run over mutliple cores to speed things up - pointer error but all files ran.
parallel::mclapply(X = tifs, FUN = adjust_extent, mc.cores = detectCores()-2)
```


This chunk of code brings in the crop production and yield rasters (only the production layers for all types) and reprojects to equal area projections for each crop)
```{r}

crop_demand <- readRDS(here("data/tidy_data/demand/total_crop_demand.rds"))

crop_list <- unique(crop_demand$map_spam_code)

crop_production_files <- list.files(file.path(mapspam_dir, "new-extents"), full.names = TRUE)[grep(pattern = "_P_", list.files(file.path(mapspam_dir, "new-extents"), full.names = TRUE))] 

these_crop_production_files <- crop_production_files[grepl("MAIZ_A|OPUL_A|WHEA_A|RAPE_A|OOIL_A|SOYB_A|SUNF_A", crop_production_files)]


#for testing the below function
this_code <- crop_list[[1]]
this_filepath <- these_crop_production_files[[5]]


#NOTE::: the function below runs fine (i.e. raster files are reprojected and produced) but introducing terra spat rasters instead of raster::rasters created an error "Error in x@ptr$nrow() : external pointer is not valid" when printing the raster. Still searching for solutions. It is to do with parallelisng SpatRaster see - https://github.com/rspatial/terra/issues/166 . So have switched to lapply to make sure code runs.

lapply(X = these_crop_production_files, FUN = \(this_filepath){
  
  this_file <- basename(this_filepath)
      
    #import the raster
    imported_file <- rast(this_filepath)
    
    #reproject the file
    reprojected_file <-  terra::aggregate(imported_file, fact = 6)
    
    #write the original and the reprojected to this project
    writeRaster(imported_file, filename = paste0(here("data/spatial/crop-layers-raw/"), this_file), overwrite = TRUE)
    writeRaster(reprojected_file, filename = paste0(here("data/spatial/crop-layers-reprojected/"), this_file), overwrite=TRUE)
  
  
})
  

#this code is need for the physical area layers stuff in the biodiversity paper so leaving in for now. 
    #imported_file <- imported_file*0.01 #converts the imported raster to km2 from ha 
    


#Pull in the MAPSPAM Yield Data from RDSI 
these_crop_yield_files <- list.files(file.path(mapspam_dir, "new-extents"), pattern = "_Y_", full.names = TRUE)
these_crop_yield_files <- these_crop_yield_files[grepl("MAIZ_A|OPUL_A|WHEA_A|RAPE_A|OOIL_A|SOYB_A|SUNF_A", these_crop_yield_files)]

this_file <- these_crop_yield_files[[1]]


map(.x = these_crop_yield_files, .f = \(this_file){
  
  this_rast <- rast(this_file)
  
  this_agg_rast <- terra::aggregate(this_rast, fact=6, fun=sum)
  
  raw_saveName <- sprintf(here("data/spatial/crop-layers-raw/%s"), basename(this_file))
  saveName <-  sprintf(here("data/spatial/crop-layers-reprojected/%s"), basename(this_file))
  
  if(!file.exists(saveName)){
    
    writeRaster(x = this_rast, filename = raw_saveName, overwrite = TRUE)
    writeRaster(x = this_agg_rast, filename = saveName, overwrite = TRUE)
    
  }
})

#Pull in the MAPSPAM Area Data from RDSI 

these_crop_area_files <- list.files(file.path(mapspam_dir, "new-extents"), pattern = "_A_", full.names = TRUE)
these_crop_area_files <- these_crop_area_files[grepl("MAIZ_A|OPUL_A|WHEA_A|RAPE_A|OOIL_A|SOYB_A|SUNF_A", these_crop_area_files)]

this_file <- these_crop_area_files[[1]]

map(.x = these_crop_area_files, .f = \(this_file){
  
  this_rast <- rast(this_file)
  
  this_agg_rast <- terra::aggregate(this_rast, fact=6, fun=sum)*0.01 #aggregate to half degree and convert to km2
  
  raw_saveName <- sprintf(here("data/spatial/crop-layers-raw/%s"), basename(this_file))
  saveName <-  sprintf(here("data/spatial/crop-layers-reprojected/%s"), basename(this_file))
  
  if(file.exists(saveName)){
    
    writeRaster(x = this_rast, filename = raw_saveName, overwrite = TRUE)
    writeRaster(x = this_agg_rast, filename = saveName, overwrite = TRUE)
    
  }
}) 

```




This is the code to unzip the gridded livestock of the world rasters - DO NOT RUN IN PROJECT - here as a backup to scripts in the raw data files

```{r}

dir <- "/mnt/rdsi/raw_data/gridded-livestock-of-the-world"

setwd(dir)

library(tidyverse)
library(parallel)
library(raster)

glw_zip_files <- list.files(dir, pattern = "\\.zip$")

unzip_raw_data <- function(this_file){
  this_file_name <- file.path(dir, this_file)
  unzip(this_file_name)
  
}


lapply(X = glw_zip_files, FUN = unzip_raw_data)



```


#Unzip FAOSTAT Production data
```{r}
unzip(list.files(path=file.path(rdsi_dir, "raw_data/fao/FAOSTAT_2022"), pattern = "Production_Crops", full.names = TRUE), exdir = file.path(rdsi_dir, "raw_data/fao/FAOSTAT_2022"))

```

#Tidy FAOSTAT Production data
```{r}

production_raw <- read_csv(file.path(rdsi_dir, "raw_data/fao/FAOSTAT_2022/Production_Crops_Livestock_E_All_Data_(Normalized).csv"))

production_flags <- read_csv(file.path(rdsi_dir, "raw_data/fao/FAOSTAT_2022/Production_Crops_Livestock_E_Flags.csv"))

production_raw <- production_raw |> 
  left_join(production_flags) |> 
  mutate(Description = if_else(is.na(Description), true = "Official data", false = Description)) |> 
  mutate(Sector = case_when(grepl("Milk|milk|Meat|meat|Fat|fat|Chicken|Buffaloes|Cattle|cattle|Camel|ffal|Pigs|abbit|worm|odent|urkey|oghurt|Wool|Sheep|Goat|Egg|egg|Asses|Beeh|Bees|Ducks|Cream|Geese|Horses|Honey|Lard|Mules|Birds|Skins|Butter|Cheese|Snail", Item) ~ "Livestock",
                            TRUE ~ "Crops"))

Encoding(production_raw$Area) <- "latin1" #deals with the non-UTF
production_raw$Area <- iconv(production_raw$Area, "latin1", "UTF-8",sub='')


#separate by sector
production_sector_list <- 
  production_raw  |> 
  clean_names()  |>  
  mutate(iso3c = countrycode(area, origin = "country.name", destination = "iso3c", warn = TRUE)) |> 
  group_split(sector)

#save
map(.x = production_sector_list, .f = function(this_element){
  saveRDS(object = this_element, file = sprintf(here("data/tidy_data/production-data/%s_production_tidy.rds"), tolower(unique(this_element$sector))))
})
  



```

#Tidying crop LCA files to include as a single file

```{r}

lca_all_crops <- 
  list.files(here("data/raw_data/LCA"), full.names = TRUE) |> 
  map_df(\(each_file){
    this_file <- read_csv(each_file) |> rename_at(vars(1:3), make_clean_names)
    this_long_file <- this_file |> 
      pivot_longer( names_to = "iso2c", values_to = "value" , cols = -c(raw_material, impact_category, unit)) |> 
      mutate(iso3c = countrycode(sourcevar = iso2c, origin = "iso2c", destination = "iso3c", warn = TRUE)) |> 
      mutate(iso3c = case_when(iso2c == "UK" ~ "GBR",
                               grepl("US-", iso2c) ~ "USA",
                               TRUE ~ iso3c))
    }) %>% 
  mutate(FAOSTAT_name = case_when(raw_material == "Broad bean" ~ "Broad beans, horse beans, dry",
                                  raw_material == "Guar seed" ~ "Pulses nes",
                                  raw_material == "Lupins" ~ "Pulses nes - Lupins",
                                  raw_material == "Peas" ~ "Peas, dry",
                                  raw_material == "Wheat grain" ~ "Wheat",
                                  TRUE ~ raw_material))
  
  

saveRDS(object = lca_all_crops, file = here("data/tidy_data/LCA/crop_lca.rds"))


unique(lca_all_crops$raw_material)
```



#FISHERIES DATA 


Pulling together the spatial industrial fisheries data and save to rdsi storage. 

```{r}

#THE v5 DATA

catch <- fread(file.path(watson_dir, "v5.0/Catch2015_2019.csv")) |> lazy_dt(immutable = FALSE) |> filter(IYear == 2017) |> as.data.table()

codes_cell <- fread(file.path(watson_dir, "v5.0/Codes_cells.csv")) |> lazy_dt(immutable = FALSE)

codes_country <- fread(file.path(watson_dir, "v5.0/Codes_country.csv"))|> lazy_dt(immutable = FALSE)

codes_gear <- fread(file.path(watson_dir, "v5.0/Codes_gear.csv")) |> lazy_dt(immutable = FALSE) |> select(Gear, FleetGearName, VBDesc) |> distinct() 

codes_taxa <- fread(file.path(watson_dir, "v5.0/Codes_taxa.csv")) |> lazy_dt(immutable = FALSE)


catch_joined<- catch |> 
  lazy_dt(immutable = FALSE) |> 
  left_join(codes_cell, by = "Cell") |>
  left_join(codes_country, by = c("CNumber" = "Cnumber")) |>
  left_join(codes_gear, by = c("Gear")) |>
  left_join(codes_taxa, by = "Taxonkey") |>
  rename(CountryName = `FAO name`) |> as.data.table()

fwrite(catch_joined, file.path(watson_dir, "v5.0/watson_2017_fisheries_catch.csv"))


# THE V4 DATA

# catch <- fread(file.path(watson_dir, "v4/Catch2015_2019.csv")) |> lazy_dt() |> filter(IYear == 2017)
# 
# codes_cell <- fread(file.path(watson_dir, "v4/codes_cells.csv")) |> lazy_dt()
# 
# codes_country <- fread(file.path(watson_dir, "v4/codes_country.csv"))|> lazy_dt()
# 
# codes_gear <- fread(file.path(watson_dir, "v4/codes_gear.csv")) |> select(Gear, FleetGearName) |> distinct() |> lazy_dt()
# 
# codes_taxa <- fread(file.path(watson_dir, "v4/codes_taxa.csv")) |> lazy_dt()
# 
# IndexInd <- fread(file.path(watson_dir, "v4/IndexInd.csv")) |> lazy_dt()
# 

# index_2015 <- 
#   IndexInd |> 
#   filter(IYear == 2015) |> 
#   left_join(codes_taxa, by = c("Taxonkey" = "TaxonKey")) |> 
#   left_join(codes_gear |> select(-c(VBCode, FAOGearName, FAOGearCode)) |> distinct(), by = c("Gear", "FGearCode")) |> 
#   left_join(codes_country, by = c("CNumber" = "Country")) |> 
#   select(-c(NumCells, Reported, IUUTotal, Discards))
#   
#  
# catch_index_join <- catch_coords_2015 |> 
#   left_join(index_2015) |> 
#   mutate(total_catch = Reported + IUU) |> 
#   as.data.table() 


#fwrite(catch_index_join, file.path(watson_dir, "watson_2015_fisheries_catch.csv"))


```

#Filter FAO Species lists for forage fish spp

```{r}
fao_list <- read_csv(file.path(fao_dir, "species_lists/CL_FI_SPECIES_GROUPS.csv"))

unique(fao_list$ISSCAAP_Group)

forage_list <- fao_list |> filter(ISSCAAP_Group == "Herrings, sardines, anchovies" )

write_csv(forage_list, here("data/raw_data/fisheries/fao_forage_fish_spp_list.csv"))
```


#Tidy embodied fish data from FMFO for different forage fish species from Kok et al 'Fish as feed: Using economic allocation to quantify the Fish In : Fish Out ratio of major fed aquaculture species' in Aquaculture. 

Data source: https://www.sciencedirect.com/science/article/pii/S0044848620309741 Appendix A Supplementary Data



```{r}
kok_etal_data <- read_csv(here("data/raw_data/fisheries/embodied_fish_kok_et_al.csv")) |> 
  mutate(Species = substring(Species, 1, nchar(Species)-1)) |> 
  mutate(common_name = case_when(grepl("Sandeels|Capelin|Boarfish", Species) ~ word(Species, start = 1, end = 1),
                                 grepl("South American pilchard", Species) ~ word(Species, start = 1, end = 3),
                                 TRUE ~ word(Species, start = 1, end = 2))) |> 
  mutate(common_name = case_when(grepl("bnchovy", common_name)~ "Peruvian anchovy",
                                TRUE ~ common_name)) |> 
  mutate(sci_name = c(unlist(str_extract_all(Species,  "(?<=\\().+?(?=\\))")), rep(NA, times = 2))) |> 
  mutate(sci_name = case_when(sci_name == "C. harengus" ~ "Clupea harengus",
                              sci_name == "M. villosus" ~ "Mallotus villosus",
                              TRUE~sci_name)) |> 
  select(-Species) |> 
  relocate(c(common_name, sci_name), .before = `Ecosystem d`)

write_csv(kok_etal_data, file = here("data/raw_data/fisheries/embodied_fish_ratio_tidy.csv"))

# now tidy ge allocation synthesised for this project.
ge_allocation_raw <- read_csv("/mnt/rdsi/raw_data/allocation/embodied_fish_ge_allocation.csv") |> 
  select(species, ecosystem, fishmeal_yield, fish_oil_yield, ingredient, value) |> 
  mutate(species = substring(species, 1, nchar(species)-1)) |> 
  mutate(common_name = case_when(grepl("Sandeels|Capelin|Boarfish", species) ~ word(species, start = 1, end = 1),
                                 grepl("South American pilchard", species) ~ word(species, start = 1, end = 3),
                                 TRUE ~ word(species, start = 1, end = 2))) |> 
  mutate(common_name = case_when(grepl("bnchovy", common_name)~ "Peruvian anchovy",
                                TRUE ~ common_name)) |> 
  mutate(sci_name = c(rep(NA, times = 2),unlist(str_extract_all(ge_allocation_raw$species,  "(?<=\\().+?(?=\\))")), rep(NA, times = 2))) |> 
  mutate(sci_name = case_when(sci_name == "C. harengus" ~ "Clupea harengus",
                              sci_name == "M. villosus" ~ "Mallotus villosus",
                              TRUE~sci_name)) |> 
  select(-species) |> 
  relocate(c(common_name, sci_name), .before = ecosystem)
  

write_csv(ge_allocation_raw, file = here("data/raw_data/allocation/embodied_fish_ge_allocation_tidy.csv"))


```



#Filter Watson spatialised catch data for forage fish species so it can be stored in the project. 

Data source: Watson v5.0 provided by request. v4.0 is publicly available through IMAS Research Data Portal https://metadata.imas.utas.edu.au/geonetwork/srv/eng/catalog.search#/metadata/5c4590d3-a45a-4d37-bf8b-ecd145cb356d

```{r}

#THE V5 DATA

catch <- fread(file.path(watson_dir, "v5.0/watson_2017_fisheries_catch.csv"))

 #145 unique species and species groups in the FAO data
forage_spp_fao <- read_csv(here("data/raw_data/fisheries/fao_forage_fish_spp_list.csv")) |> select(Name_en, Scientific_Name) |> distinct() |> rename(common_name = Name_en, sci_name = Scientific_Name) 

#bring in species highlighted in the SI of Froehlich et al 2018 Avoiding the ecological limits of forage fish. Nature Sustainability.
froehlich_spp <- read_csv("/mnt/rdsi/raw_data/froehlich/forage_fish_spp.csv")

froehlich_binomials <- froehlich_spp |> filter(resolution == "binomial") |> mutate(common_name = NA) |> select(common_name, sci_name)


#13 species in Kok et al - some not in the FAO data
forage_spp_koketal <- read_csv(here("data/raw_data/fisheries/embodied_fish_ratio_tidy.csv")) |> drop_na() |>  select(common_name, sci_name) |> distinct()
#forage_spp_koketal_common <- read_csv(here("data/raw_data/fisheries/embodied_fish_ratio_tidy.csv")) |> drop_na() |>  pull(common_name) |> unique()

#bind the two sources and save - 155 species considered in total
forage_spp_list <- bind_rows(forage_spp_fao, froehlich_binomials ,forage_spp_koketal) |> distinct()
write_csv(forage_spp_list, here("data/raw_data/fisheries/forage_fish_list_final.csv"))

forage_catch <- catch |> 
  lazy_dt(immutable = FALSE) |> 
  filter(TaxonName %in% forage_spp_list$sci_name | CommonName %in% forage_spp_list$common_name ) |> 
  mutate(total_catch = ReportedIND+IUUIND+ReportedNIND+IUUNIND, total_ind = ReportedIND+IUUIND, total_nind =ReportedNIND+IUUNIND) |>
  as_tibble()

#23 million tonnes, represented by 46 species across industrial and non industrial sources
sum(forage_catch$total_catch)
sum(forage_catch$total_ind) #22.5 mill is from industrial
sum(forage_catch$total_nind) #1.3 mill is from non-industrial
unique(forage_catch$TaxonName) 

saveRDS(forage_catch, file = here("data/raw_data/fisheries/spatial_forage_catch_2017.rds"))



```

#Tidy Global fishing watch data.

Data source: https://globalfishingwatch.org/data-download/datasets/public-fishing-effort
Files: fleet-daily-csvs-100-v2-2017.zip, fish-vessels-v2.csv, README-fleet-v2.txt

First we can summarise the efort hours per day and bind it together.
```{r}

daily_effort_files <- list.files(file.path(gfw_dir, "fleet-daily-csvs-100-v2-2017"), pattern = ".csv", full.names = TRUE)

#summarise effort by day

effort_by_daygearcell <- 
  map_df(.x = daily_effort_files, .f = \(this_effort_filepath){
    
    
  saveName <-  paste0("summarised_", basename(this_effort_filepath))  
  
  this_counter <- which(daily_effort_files == this_effort_filepath)

  this_days_data <- fread(this_effort_filepath) 
  
  #this_days_data <- read_csv(this_effort_filepath, col_types = "Dddccddn")
  
  this_days_summarised_data <- 
    this_days_data |> 
    lazy_dt(immutable = FALSE) |> 
    group_by(cell_ll_lat, cell_ll_lon, geartype) |> 
    summarise(total_fishing_hrs = sum(fishing_hours, na.rm = TRUE)) |> 
    ungroup() |> 
    mutate(day = this_counter) |> 
    as.data.table()
  
  return(this_days_summarised_data)
  
}) 

#summarised annually - seems to be the same number of rows - could be the number of 0s
effort_by_gearcell2017 <- 
  effort_by_daygearcell |> 
  lazy_dt(immutable = FALSE) |> 
  group_by(cell_ll_lat, cell_ll_lon, geartype) |> 
  summarise(total_fishing_hrs = sum(total_fishing_hrs)) |> 
  as.data.table()


fwrite(x = effort_by_gearcell2017, file = here("data/tidy_data/pressures/fishing-effort/annual_effort_2017.csv"))

```

Explore the GFW data for gear types partitioning across gears and output effort rasters for destructive methods for the benthos.

From Mel's script in the OHI_Science/food_systems folder the following gear types are used:

Geartypes:
- fishing: a combination of vessels of unknown fishing gear
 - drifting_longlines: drifting longlines
 - seiners: vessels using seine nets, including potential purse seine vessels
   targeting tuna and other species, as well as danish and other seines
     - purse_seines: purse seines, both pelagic and demersal
        - tuna_purse_seines: large purse seines primarily fishing for tuna.
        - other_purse_seines: purse seiners fishing for mackerel, anchovies, etc, often smaller and operating nearer the coast than tuna purse seines.
    - other_seines: danish seines and other seiners not using purse seines.
 - trawlers: trawlers, all types
 - pole_and_line: vessel from which people fish with pole and line.
 - trollers: vessel that tows multiple fishing lines.
 - fixed_gear: a category that includes potential set longlines, set gillnets,  and pots and traps
     - pots_and_traps: vessel that deploys pots (small, portable traps) or traps to
       catch fish
     - set_longlines: vessel that fishes by setting longlines anchored to the
       seafloor. These lines have shorter hooked, typically baited, lines hanging
       from them
     - set_gillnets: vessel that fishes by setting gillnets anchored to the seafloor.
 - dredge_fishing: vessel that tows a dredge the scrapes up edible bottom
   dwellers such as scallops or oysters.
 - squid_jigger: squid jiggers, mostly large industrial pelagic operating vessels


The influence of unknown fishing gears ('fishing' above) was addressed in Halpern et al as a small source of   uncertainty. See issue here https://github.com/OHI-Science/global_food_issues/issues/303

```{r}

effort_summary <- fread(here("data/tidy_data/pressures/fishing-effort/annual_effort_2017.csv"))

#nearly 50% of all fishing effort is trawling (yikes), another 20% is drifting longlines
effort_summary |> 
  lazy_dt(immutable = TRUE) |> 
  group_by(geartype) |> 
  summarize(total_fishing_hrs = sum(total_fishing_hrs, na.rm=TRUE)) |> 
  arrange(-total_fishing_hrs) |> 
  mutate(prop_hrs = total_fishing_hrs/sum(total_fishing_hrs)) |> 
  as.data.table() 


#create raster of all fishing effort
total_map <- 
  effort_summary |> 
  lazy_dt(immutable = FALSE) |> 
  group_by(cell_ll_lon, cell_ll_lat) |> 
  summarize(total_fishing_hrs = sum(total_fishing_hrs, na.rm = TRUE)) |> 
  rename(lat = cell_ll_lat,
         lon = cell_ll_lon) |> 
  select(lon, lat, total_fishing_hrs) |> data.frame()
  
total_effort_r <- rast(total_map, type = "xyz", crs = crs(rast()))
plot(log10(total_effort_r+1))


#we are only interested in destructive gears for the benthic elemnt of disturbance so isolate maps for trawling and dredging

#trawling

trawl_map <- 
  effort_summary |> 
  lazy_dt(immutable = FALSE) |> 
  filter(geartype %in% c("trawlers")) |> 
  group_by(cell_ll_lon, cell_ll_lat) |> 
  summarize(total_fishing_hrs = sum(total_fishing_hrs, na.rm = TRUE)) |> 
  rename(lat = cell_ll_lat,
         lon = cell_ll_lon) |> 
  select(lon, lat, total_fishing_hrs) |> data.frame()
  
trawl_effort_r <- rast(trawl_map, type = "xyz", crs = crs(rast()))

trawl_effort_r <- extend(trawl_effort_r, ext(rast(res=0.01)), filename = here("data/spatial/03-fisheries-effort/gfw_annual_effort_2017_trawlers.tif"), overwrite=TRUE)
plot(log10(trawl_effort_r+1))



#dredging (much less prevalent)

dredge_map <- 
  effort_summary |> 
  lazy_dt(immutable = FALSE) |> 
  filter(geartype %in% c("dredge_fishing")) |> 
  group_by(cell_ll_lon, cell_ll_lat) |> 
  summarize(total_fishing_hrs = sum(total_fishing_hrs, na.rm = TRUE)) |> 
  rename(lat = cell_ll_lat,
         lon = cell_ll_lon) |> 
  select(lon, lat, total_fishing_hrs) |> data.frame()
  
dredge_effort_r <- rast(dredge_map, type = "xyz", crs = crs(rast()))
dredge_effort_r <- extend(dredge_effort_r, ext(rast(res=0.01)), filename = here("data/spatial/03-fisheries-effort/gfw_annual_effort_2017_dredge.tif"), overwrite=TRUE)
plot(log10(dredge_effort_r+1))




```

# Bring in rob parker data from rdsi storage in raw_data


```{r}
#importing the join data from downloaded data in RDSI storage
parker_gear_join <- read_csv(file.path(food_systems_data_dir, "parker_gear_join.csv"))

#alternatively it can be dowloaded from here when the food systems project is published
#parker_gear_join <- read_csv("https://raw.githubusercontent.com/OHI-Science/food_systems/master/fisheries/marine/ghg/int/gear_index_parker.csv?token=GHSAT0AAAAAABWBCADKLIWM2Y6WTU7X6FXAYWFFRVQ")


write_csv(parker_gear_join, file = here("data/raw_data/fisheries/parker_gear_join.csv"))



#Bring emissions intensity data from Parker et al 2018 stored in RDSI and save to project
ei_data <- 
  fread(file.path(food_systems_data_dir, "all_catch_emissions_2017.csv")) |> 
  lazy_dt(immutable = FALSE) |> 
  select(Taxonkey, Descript, species_class_int, species_class_fin, ParkerGearName = gear_type, ei_kgco2_kgcatch) |> 
  distinct() |> 
  arrange(ParkerGearName)|> 
  as_tibble()
  
write_csv(x= ei_data, file = here("data/raw_data/fisheries/all_catch_emissions_2017.csv"))




```


#Import the global net primary productivity data

The NPP data was taken from the Cumulative Human Impacts Project at NCEAS. Downloaded from the aurora server. 

The raster has been gapfilled to make all the NA values mean porductivity values
```{r}

npp_r <- rast(file.path(rdsi_raw_data_dir, "food-systems-project/annal_mean_npp_2015_gf_wgs.tif"))
plot(npp_r)
writeRaster(x = npp_r, filename = here("data/spatial/00-net-primary-producivity/annal_mean_npp_2015_gf_wgs.tif"))


```

# Pull in allocation data from Kok et al (economic allocation on forage fish) and synthesised data from Teams for gross energy calculation.

Interesting paper by Ayer, Tyedmers et al on the benefits of gross energy allocation https://link.springer.com/content/pdf/10.1065/lca2006.11.284.pdf


```{r}

ingredient_cf_data <- read_csv("/mnt/rdsi/raw_data/allocation/top_crop_producers_conversions.csv")
write_csv(ingredient_cf_data, here("data/tidy_data/production-data/top_crop_producers_conversions.csv"))  

cf_coproduct_data <- read_csv("/mnt/rdsi/raw_data/allocation/coproduct_conversions.csv") |> select(ingredient, coproduct,country, coproduct_cf)
write_csv(x = cf_coproduct_data, file = here("data/raw_data/allocation/coproduct_conversions.csv"))

ge_values <- read_csv("/mnt/rdsi/raw_data/allocation/feed_coproduct_ge_allocation.csv") |> 
  mutate(coproduct = if_else(ingredient == "guar meal", true = "guar gum", false = coproduct)) 
write_csv(ge_values, file = here("data/raw_data/allocation/feed_coproduct_ge_allocation.csv"))



```


